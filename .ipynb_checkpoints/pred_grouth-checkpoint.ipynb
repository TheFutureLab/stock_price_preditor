{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep = pd.read_csv('data/market_data/KO.csv')\n",
    "ko = pd.read_csv('data/market_data/PEP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=ko,right=pep,left_on='dt',right_on='dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df.close_x/df.close_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt'] = pd.to_datetime(df.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.dt.dt.month\n",
    "df['year'] = df.dt.dt.year\n",
    "df['dow'] = df.dt.dt.dayofweek\n",
    "df['hour'] = df.dt.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['month','year','dow','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['ratio_grouth'] = 1\n",
    "df['ratio_grouth'].iloc[1:] = np.array(df['ratio'].iloc[1:])/np.array(df['ratio'].iloc[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa22e1ad898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(x='dt',y='ratio_grouth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,value, _ = coint(df[df.dt.dt.year>2013].open_y,df[df.dt.dt.year>2013].open_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(batch_size,num_steps,input_size):\n",
    "    inputs = tf.placeholder(shape=(batch_size,num_steps,input_size),dtype=tf.float32,name='inputs')\n",
    "    targets = tf.placeholder(shape=(batch_size,1),dtype=tf.float32,name='targets')\n",
    "    \n",
    "    return inputs,targets\n",
    "\n",
    "def build_lstm(lstm_size,num_layers,batch_size):\n",
    "    \n",
    "    stacked_rnn = []\n",
    "    for layer in range(num_layers):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=0.7)\n",
    "        stacked_rnn.append(drop)\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells=stacked_rnn, state_is_tuple=True)\n",
    "    \n",
    "    initial_state = cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    \n",
    "    return cell, initial_state\n",
    "\n",
    "def build_output(lstm_output,in_size,out_size=1):\n",
    "    #seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x1 = tf.reshape(tensor=lstm_output,shape=(-1,in_size))\n",
    "    x1 = tf.contrib.layers.fully_connected(x1,int(in_size*1.5))\n",
    "    x1 = tf.layers.batch_normalization(x1)\n",
    "    x1 = tf.maximum(x1,x1*0.2)\n",
    "    x1 = tf.nn.dropout(x1,0.8)\n",
    "    \n",
    "    x1 = tf.contrib.layers.fully_connected(x1,int(in_size*1.3))\n",
    "    x1 = tf.layers.batch_normalization(x1)\n",
    "    x1 = tf.maximum(x1,x1*0.2)\n",
    "    x1 = tf.nn.dropout(x1,0.8)\n",
    "    \n",
    "    x = tf.contrib.layers.fully_connected(x1,in_size)\n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    x = tf.maximum(x,x*0.2)\n",
    "    x = tf.nn.dropout(x,0.6)\n",
    "                    \n",
    "    with tf.variable_scope('logits'):\n",
    "        logits_w = tf.Variable(tf.truncated_normal((in_size,out_size),stddev=0.1))\n",
    "        logits_b = tf.Variable(tf.zeros(out_size))\n",
    "        \n",
    "    logits = tf.add(tf.matmul(x,logits_w),logits_b)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def build_loss(logits,targets):\n",
    "    loss = tf.reduce_mean(tf.squared_difference(logits,targets))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def build_optimizer(loss, grad_clip):\n",
    "\n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(0.000001)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "class Network:\n",
    "    def __init__(self,batch_size,num_steps,lstm_size,num_layers,input_size,grad_clip=5):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs,self.targets = build_inputs(batch_size,num_steps,input_size)\n",
    "        \n",
    "        cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size)\n",
    "        \n",
    "        outputs, state = tf.nn.dynamic_rnn(cell=cell,initial_state=self.initial_state,inputs=self.inputs)\n",
    "        \n",
    "        self.final_state = state\n",
    "        \n",
    "        self.logits = build_output(outputs,num_steps*lstm_size,1)\n",
    "        \n",
    "        self.loss = build_loss(self.logits,self.targets)\n",
    "        \n",
    "        self.opt = build_optimizer(self.loss, grad_clip)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['high_x','low_x','volume_x','high_y','low_y','volume_y', 'month_1', 'month_2',\n",
    "       'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8',\n",
    "       'month_9', 'month_10', 'month_11', 'month_12', 'year_2010', 'year_2011',\n",
    "       'year_2012', 'year_2013', 'year_2014', 'year_2015', 'year_2016',\n",
    "       'year_2017', 'dow_0', 'dow_1', 'dow_2', 'dow_3', 'dow_4', 'hour_9',\n",
    "       'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
    "       'hour_16','ratio_grouth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[['high_x','low_x','volume_x','high_y','low_y','volume_y']] = scaler.fit_transform(df[['high_x','low_x','volume_x','high_y','low_y','volume_y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_length = 50\n",
    "input_size = len(cols)\n",
    "\n",
    "n_batches = len(df)//(batch_size*input_length)\n",
    "size = batch_size*n_batches*input_length\n",
    "\n",
    "df = df[-1*size-2:]\n",
    "\n",
    "model = Network(batch_size=batch_size, num_steps=input_length,\n",
    "                lstm_size=64, num_layers=3, \n",
    "                input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    for i in range(len(df)-input_length*batch_size-1):\n",
    "        batch = df.iloc[i:i+input_length*batch_size+1,1:]\n",
    "        \n",
    "        x = np.reshape(np.array(batch[cols].iloc[:-1]), (batch_size,input_length,input_size) )\n",
    "        y = np.reshape(np.array(batch['ratio_grouth'].iloc[1:]), (batch_size,input_length,1) )[:,-1,:]\n",
    "\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 n 0 pred [-0.03932267] y [1.00072192]\n",
      "e 0 n 200 pred [0.8335375] y [0.99900939]\n",
      "e 0 n 400 pred [0.97775704] y [1.00021762]\n",
      "e 0 n 600 pred [0.9938526] y [1.00051352]\n",
      "e 0 n 800 pred [0.9581176] y [1.00030326]\n",
      "e 0 n 1000 pred [0.93426484] y [1.01002872]\n",
      "e 0 n 1200 pred [1.089231] y [1.00117947]\n",
      "e 0 n 1400 pred [1.1748815] y [0.99902285]\n",
      "e 0 n 1600 pred [1.0906965] y [0.99744173]\n",
      "e 0 n 1800 pred [1.0084718] y [1.00106211]\n",
      "e 0 n 2000 pred [1.0983676] y [1.00153418]\n",
      "e 0 n 2200 pred [1.1486262] y [1.00158647]\n",
      "e 0 n 2400 pred [1.0332608] y [0.99942879]\n",
      "e 0 n 2600 pred [0.99576664] y [0.99958446]\n",
      "e 0 n 2800 pred [1.128871] y [0.99923121]\n",
      "e 0 n 3000 pred [1.0156109] y [0.99910217]\n",
      "e 0 n 3200 pred [0.939179] y [1.00134804]\n",
      "e 0 n 3400 pred [0.9347189] y [0.99933574]\n",
      "e 0 n 3600 pred [0.8832835] y [1.00098822]\n",
      "e 0 n 3800 pred [0.9877655] y [0.99991441]\n",
      "e 0 n 4000 pred [0.9400953] y [1.00151856]\n",
      "e 0 n 4200 pred [0.9757115] y [0.99906598]\n",
      "e 0 n 4400 pred [0.96202624] y [0.99953338]\n",
      "e 0 n 4600 pred [0.9716288] y [1.00046631]\n",
      "e 0 n 4800 pred [1.0831652] y [0.99981377]\n",
      "e 0 n 5000 pred [0.9058905] y [0.99983971]\n",
      "e 0 n 5200 pred [1.0174639] y [0.99831714]\n",
      "e 0 n 5400 pred [0.9793383] y [1.0006117]\n",
      "e 0 n 5600 pred [0.96553767] y [1.00080338]\n",
      "e 0 n 5800 pred [0.93928087] y [0.99919751]\n",
      "e 0 n 6000 pred [0.8828301] y [0.99959041]\n",
      "e 0 n 6200 pred [1.0018411] y [0.99891068]\n",
      "e 0 n 6400 pred [1.0052352] y [1.00286188]\n",
      "e 0 n 6600 pred [1.0275627] y [1.00038751]\n",
      "e 0 n 6800 pred [1.1122757] y [1.00030093]\n",
      "e 0 n 7000 pred [0.9627259] y [1.00137166]\n",
      "e 0 n 7200 pred [0.9757043] y [1.00088546]\n",
      "e 0 n 7400 pred [0.990297] y [1.00059328]\n",
      "e 0 n 7600 pred [1.1277236] y [1.00062029]\n",
      "e 0 n 7800 pred [0.9954296] y [1.00117674]\n",
      "e 0 n 8000 pred [1.0604727] y [1.00058009]\n",
      "e 0 n 8200 pred [1.0700325] y [0.99750269]\n",
      "e 0 n 8400 pred [1.1375544] y [1.00221893]\n",
      "e 0 n 8600 pred [0.93191797] y [0.99984657]\n",
      "e 0 n 8800 pred [1.0371238] y [1.0001516]\n",
      "e 0 n 9000 pred [0.97062457] y [1.00402001]\n",
      "e 0 n 9200 pred [1.0209024] y [1.00303132]\n",
      "e 0 n 9400 pred [1.0982338] y [1.00082783]\n",
      "e 0 n 9600 pred [1.0399802] y [1.00284661]\n",
      "e 0 n 9800 pred [1.0354348] y [0.99934204]\n",
      "e 0 n 10000 pred [0.9822] y [1.00097242]\n",
      "e 0 n 10200 pred [1.0394065] y [1.0019402]\n",
      "e 0 n 10400 pred [1.0771276] y [1.00054425]\n",
      "e 0 n 10600 pred [1.0102078] y [0.99667798]\n",
      "e 0 n 10800 pred [1.0136274] y [1.00149223]\n",
      "e 0 n 11000 pred [1.0463511] y [0.98260827]\n",
      "e 0 n 11200 pred [1.0431993] y [1.00034015]\n",
      "e 0 n 11400 pred [1.0093961] y [0.99931553]\n",
      "e 0 n 11600 pred [1.0453035] y [0.99905131]\n",
      "e 0 n 11800 pred [0.8681112] y [0.99955435]\n",
      "e 0 n 12000 pred [1.025401] y [1.00040618]\n",
      "e 0 n 12200 pred [0.99410415] y [1.00058586]\n",
      "e 0 n 12400 pred [0.9655485] y [1.00276516]\n",
      "e 0 n 12600 pred [0.96892625] y [0.99823662]\n",
      "e 0 n 12800 pred [1.0276054] y [0.99963299]\n",
      "e 0 n 13000 pred [0.9520295] y [0.99940519]\n",
      "e 0 n 13200 pred [0.9729388] y [1.0000254]\n",
      "e 0 n 13400 pred [0.92862314] y [1.00025478]\n",
      "e 0 n 13600 pred [1.0620319] y [0.99987575]\n",
      "e 0 n 13800 pred [0.8953938] y [0.99939557]\n",
      "e 0 n 14000 pred [1.0175502] y [0.99870122]\n",
      "e 0 n 14200 pred [1.1477252] y [1.00061643]\n",
      "e 0 n 14400 pred [0.99124664] y [1.00007187]\n",
      "e 0 n 14600 pred [1.0198077] y [0.99951764]\n",
      "e 0 n 14800 pred [0.97695065] y [1.00000906]\n",
      "e 0 n 15000 pred [1.0243884] y [1.00037611]\n",
      "e 0 n 15200 pred [0.9577828] y [1.0006766]\n",
      "e 0 n 15400 pred [0.9971282] y [1.00175713]\n",
      "e 0 n 15600 pred [0.99356264] y [0.99887758]\n",
      "e 0 n 15800 pred [0.98969287] y [1.00006934]\n",
      "e 0 n 16000 pred [0.9807223] y [0.99846783]\n",
      "e 0 n 16200 pred [1.000227] y [1.00114295]\n",
      "e 0 n 16400 pred [0.9676266] y [1.00000261]\n",
      "e 0 n 16600 pred [1.078814] y [0.99880802]\n",
      "e 0 n 16800 pred [1.0371158] y [0.99983777]\n",
      "e 0 n 17000 pred [0.93489337] y [1.00198776]\n",
      "e 0 n 17200 pred [1.0075345] y [0.99934144]\n",
      "e 0 n 17400 pred [1.0071077] y [1.00491125]\n",
      "e 0 n 17600 pred [0.9548407] y [1.00196965]\n",
      "e 0 n 17800 pred [0.9003576] y [1.00139025]\n",
      "e 0 n 18000 pred [0.99263877] y [1.00077405]\n",
      "e 0 n 18200 pred [1.013033] y [0.9993385]\n",
      "e 0 n 18400 pred [1.0014405] y [1.00027379]\n",
      "e 0 n 18600 pred [1.0342798] y [0.99923005]\n",
      "e 0 n 18800 pred [0.97040534] y [1.00026681]\n",
      "e 0 n 19000 pred [0.9650622] y [1.00012962]\n",
      "e 0 n 19200 pred [1.021561] y [0.99865327]\n",
      "e 0 n 19400 pred [1.0078297] y [1.00153058]\n",
      "e 0 n 19600 pred [1.0744811] y [0.99897718]\n",
      "e 0 n 19800 pred [0.97611755] y [1.00141362]\n",
      "e 0 n 20000 pred [1.0117997] y [0.99936823]\n",
      "e 0 n 20200 pred [0.9878331] y [0.99996916]\n",
      "e 0 n 20400 pred [1.0038723] y [1.00039758]\n",
      "e 0 n 20600 pred [0.98587495] y [0.99988325]\n",
      "e 0 n 20800 pred [1.0526187] y [1.00158336]\n",
      "e 0 n 21000 pred [0.99798363] y [0.99842145]\n",
      "e 0 n 21200 pred [1.0108265] y [0.99447295]\n",
      "e 0 n 21400 pred [0.9663417] y [1.00049123]\n",
      "e 0 n 21600 pred [1.0268002] y [0.9987318]\n",
      "e 0 n 21800 pred [1.1057131] y [0.99939769]\n",
      "e 0 n 22000 pred [1.0082899] y [1.00321769]\n",
      "e 0 n 22200 pred [0.9709994] y [1.00076292]\n",
      "e 0 n 22400 pred [0.9445713] y [0.99926742]\n",
      "e 0 n 22600 pred [0.9421158] y [1.00044928]\n",
      "e 0 n 22800 pred [1.0072765] y [0.99908409]\n",
      "e 0 n 23000 pred [0.98756677] y [0.99935909]\n",
      "e 0 n 23200 pred [0.98903686] y [0.99810104]\n",
      "e 0 n 23400 pred [1.0574913] y [1.00645633]\n",
      "e 0 n 23600 pred [0.9961342] y [0.9994623]\n",
      "e 0 n 23800 pred [1.0085262] y [1.00382306]\n",
      "e 0 n 24000 pred [1.0288527] y [1.00014376]\n",
      "e 0 n 24200 pred [1.0658038] y [0.99913745]\n",
      "e 0 n 24400 pred [1.0688887] y [0.99911151]\n",
      "e 0 n 24600 pred [1.037065] y [1.00007402]\n",
      "e 0 n 24800 pred [0.99630284] y [1.00042394]\n",
      "e 0 n 25000 pred [0.9533404] y [1.00134289]\n",
      "e 0 n 25200 pred [0.9764428] y [1.00017781]\n",
      "e 0 n 25400 pred [0.9327313] y [1.00250526]\n",
      "e 0 n 25600 pred [0.96392226] y [0.99837791]\n",
      "e 0 n 25800 pred [1.0423889] y [0.99990516]\n",
      "e 0 n 26000 pred [1.0067132] y [0.99863584]\n",
      "e 0 n 26200 pred [1.0005399] y [1.0025812]\n",
      "e 0 n 26400 pred [0.9742614] y [1.00048263]\n",
      "e 0 n 26600 pred [0.96816945] y [0.99726387]\n",
      "e 0 n 26800 pred [0.9844288] y [0.99904676]\n",
      "e 0 n 27000 pred [0.9890199] y [1.00096071]\n",
      "e 0 n 27200 pred [1.0296617] y [0.99772217]\n",
      "e 0 n 27400 pred [1.0035204] y [1.00152503]\n",
      "e 0 n 27600 pred [1.0157117] y [0.99990448]\n",
      "e 0 n 27800 pred [0.9518868] y [1.00100518]\n",
      "e 0 n 28000 pred [0.9337541] y [0.99941292]\n",
      "e 0 n 28200 pred [0.9172544] y [0.99951916]\n",
      "e 0 n 28400 pred [1.0317589] y [0.99971501]\n",
      "e 0 n 28600 pred [0.93202] y [0.99968314]\n",
      "e 0 n 28800 pred [0.9696451] y [0.99922161]\n",
      "e 0 n 29000 pred [0.98555535] y [0.99927885]\n",
      "e 0 n 29200 pred [1.0237353] y [0.99933793]\n",
      "e 0 n 29400 pred [1.0324496] y [0.99989204]\n",
      "e 0 n 29600 pred [0.9467982] y [1.00024454]\n",
      "e 0 n 29800 pred [1.0118665] y [1.0021755]\n",
      "e 0 n 30000 pred [0.9986272] y [1.01215043]\n",
      "e 0 n 30200 pred [1.0111479] y [1.00179286]\n",
      "e 0 n 30400 pred [1.0183814] y [0.99970387]\n",
      "e 0 n 30600 pred [0.9696825] y [1.00047395]\n",
      "e 0 n 30800 pred [1.0001109] y [0.99788239]\n",
      "e 0 n 31000 pred [0.9937935] y [1.00541544]\n",
      "e 0 n 31200 pred [0.9733947] y [0.99799607]\n",
      "e 0 n 31400 pred [1.0802091] y [0.99928333]\n",
      "e 0 n 31600 pred [1.023419] y [0.99973626]\n",
      "e 0 n 31800 pred [1.0013039] y [0.99992112]\n",
      "e 0 n 32000 pred [0.96618664] y [0.99826323]\n",
      "e 0 n 32200 pred [1.012146] y [1.00212437]\n",
      "e 0 n 32400 pred [1.0193105] y [0.99909982]\n",
      "e 0 n 32600 pred [0.97185874] y [0.99913419]\n",
      "e 0 n 32800 pred [0.9488874] y [1.00027122]\n",
      "e 0 n 33000 pred [1.0142326] y [0.99899116]\n",
      "e 0 n 33200 pred [0.95726323] y [1.00727656]\n",
      "e 0 n 33400 pred [1.0596904] y [0.99956431]\n",
      "e 0 n 33600 pred [1.0217484] y [1.00157124]\n",
      "e 0 n 33800 pred [1.0031103] y [1.00049642]\n",
      "e 0 n 34000 pred [0.9800273] y [0.99955513]\n",
      "e 0 n 34200 pred [1.0021447] y [0.99974802]\n",
      "e 0 n 34400 pred [0.93935925] y [1.00036449]\n",
      "e 0 n 34600 pred [1.0135877] y [1.00251142]\n",
      "e 0 n 34800 pred [1.0246178] y [1.00071499]\n",
      "e 0 n 35000 pred [0.97018874] y [0.9985603]\n",
      "e 0 n 35200 pred [1.0353596] y [1.00064503]\n",
      "e 0 n 35400 pred [0.9785204] y [1.00059707]\n",
      "e 0 n 35600 pred [1.0387866] y [1.00073957]\n",
      "e 0 n 35800 pred [0.98510236] y [1.01301473]\n",
      "e 0 n 36000 pred [1.0192509] y [0.99874791]\n",
      "e 0 n 36200 pred [1.0198786] y [1.000567]\n",
      "e 0 n 36400 pred [1.0224121] y [1.00205536]\n",
      "e 0 n 36600 pred [1.0452583] y [1.00121351]\n",
      "e 0 n 36800 pred [0.9734057] y [1.00005837]\n",
      "e 0 n 37000 pred [1.0402179] y [0.99957705]\n",
      "e 0 n 37200 pred [1.0480415] y [0.99963435]\n",
      "e 0 n 37400 pred [1.012133] y [1.00070226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0 n 37600 pred [1.0002139] y [0.99857378]\n",
      "e 0 n 37800 pred [1.0093558] y [0.99936839]\n",
      "e 0 n 38000 pred [0.95856524] y [0.99927964]\n",
      "e 0 n 38200 pred [1.018795] y [1.00350896]\n",
      "e 0 n 38400 pred [1.0130795] y [0.99983769]\n",
      "e 0 n 38600 pred [1.021409] y [1.00044822]\n",
      "e 0 n 38800 pred [0.96881247] y [1.00065078]\n",
      "e 0 n 39000 pred [1.0077204] y [0.99852306]\n",
      "e 0 n 39200 pred [1.0577523] y [0.99973262]\n",
      "e 0 n 39400 pred [1.001923] y [0.99965672]\n",
      "e 0 n 39600 pred [1.0126661] y [0.99946376]\n",
      "e 0 n 39800 pred [0.9701726] y [0.99975566]\n",
      "e 0 n 40000 pred [0.99385077] y [0.99949535]\n",
      "e 0 n 40200 pred [1.0104072] y [0.99916456]\n",
      "e 0 n 40400 pred [1.0437139] y [1.00076421]\n",
      "e 0 n 40600 pred [0.96452767] y [1.00077829]\n",
      "e 0 n 40800 pred [1.0331881] y [1.0016409]\n",
      "e 0 n 41000 pred [0.97618103] y [1.00084602]\n",
      "e 0 n 41200 pred [1.050968] y [0.99830401]\n",
      "e 0 n 41400 pred [1.0199945] y [0.99987012]\n",
      "e 0 n 41600 pred [1.028857] y [1.001125]\n",
      "e 0 n 41800 pred [1.0190097] y [1.00014154]\n",
      "e 0 n 42000 pred [0.9732297] y [0.99957319]\n",
      "e 0 n 42200 pred [1.005089] y [0.99944181]\n",
      "e 0 n 42400 pred [1.0268248] y [1.00021338]\n",
      "e 0 n 42600 pred [0.9679549] y [1.0007699]\n",
      "e 0 n 42800 pred [1.0159513] y [1.00019987]\n",
      "e 0 n 43000 pred [0.9824365] y [0.9997942]\n",
      "e 0 n 43200 pred [0.9689978] y [1.00218702]\n",
      "e 0 n 43400 pred [1.0486549] y [0.99837254]\n",
      "e 0 n 43600 pred [1.0046387] y [1.00055638]\n",
      "e 0 n 43800 pred [0.9709138] y [1.00092206]\n",
      "e 0 n 44000 pred [1.0346688] y [1.00023935]\n",
      "e 0 n 44200 pred [1.0245439] y [0.99753731]\n",
      "e 0 n 44400 pred [1.0233725] y [0.99902898]\n",
      "e 0 n 44600 pred [0.93739253] y [0.99936908]\n",
      "e 0 n 44800 pred [1.0292281] y [0.99935021]\n",
      "e 0 n 45000 pred [1.0492071] y [0.99997974]\n",
      "e 0 n 45200 pred [1.0259302] y [1.00126568]\n",
      "e 0 n 45400 pred [1.0105685] y [0.99888227]\n",
      "e 0 n 45600 pred [1.0469792] y [1.00103054]\n",
      "e 0 n 45800 pred [1.0758305] y [0.99960078]\n",
      "e 0 n 46000 pred [1.0236251] y [1.00006502]\n",
      "mean 0.05132253336803103 batch_loss 0.020956034481096262\n",
      "e 1 n 0 pred [1.0385034] y [1.00072192]\n",
      "e 1 n 200 pred [1.0020096] y [0.99900939]\n",
      "e 1 n 400 pred [0.9607294] y [1.00021762]\n",
      "e 1 n 600 pred [1.0162919] y [1.00051352]\n",
      "e 1 n 800 pred [0.99051267] y [1.00030326]\n",
      "e 1 n 1000 pred [1.0293255] y [1.01002872]\n",
      "e 1 n 1200 pred [1.013656] y [1.00117947]\n",
      "e 1 n 1400 pred [0.9545252] y [0.99902285]\n",
      "e 1 n 1600 pred [0.972561] y [0.99744173]\n",
      "e 1 n 1800 pred [1.0203928] y [1.00106211]\n",
      "e 1 n 2000 pred [0.95078975] y [1.00153418]\n",
      "e 1 n 2200 pred [0.98717046] y [1.00158647]\n",
      "e 1 n 2400 pred [0.98969746] y [0.99942879]\n",
      "e 1 n 2600 pred [0.9769272] y [0.99958446]\n",
      "e 1 n 2800 pred [0.97294825] y [0.99923121]\n",
      "e 1 n 3000 pred [0.9974905] y [0.99910217]\n",
      "e 1 n 3200 pred [0.9747472] y [1.00134804]\n",
      "e 1 n 3400 pred [0.97298497] y [0.99933574]\n",
      "e 1 n 3600 pred [0.991136] y [1.00098822]\n",
      "e 1 n 3800 pred [0.9913938] y [0.99991441]\n",
      "e 1 n 4000 pred [1.0045985] y [1.00151856]\n",
      "e 1 n 4200 pred [0.9900171] y [0.99906598]\n",
      "e 1 n 4400 pred [0.99295264] y [0.99953338]\n",
      "e 1 n 4600 pred [0.9987941] y [1.00046631]\n",
      "e 1 n 4800 pred [1.023026] y [0.99981377]\n",
      "e 1 n 5000 pred [0.985942] y [0.99983971]\n",
      "e 1 n 5200 pred [0.9477271] y [0.99831714]\n",
      "e 1 n 5400 pred [0.9904851] y [1.0006117]\n",
      "e 1 n 5600 pred [1.0346372] y [1.00080338]\n",
      "e 1 n 5800 pred [0.9649187] y [0.99919751]\n",
      "e 1 n 6000 pred [1.0362971] y [0.99959041]\n",
      "e 1 n 6200 pred [0.9703422] y [0.99891068]\n",
      "e 1 n 6400 pred [1.046985] y [1.00286188]\n",
      "e 1 n 6600 pred [1.033895] y [1.00038751]\n",
      "e 1 n 6800 pred [1.0002645] y [1.00030093]\n",
      "e 1 n 7000 pred [1.0219376] y [1.00137166]\n",
      "e 1 n 7200 pred [0.9983139] y [1.00088546]\n",
      "e 1 n 7400 pred [1.013071] y [1.00059328]\n",
      "e 1 n 7600 pred [1.0063617] y [1.00062029]\n",
      "e 1 n 7800 pred [0.9826796] y [1.00117674]\n",
      "e 1 n 8000 pred [1.0047936] y [1.00058009]\n",
      "e 1 n 8200 pred [0.9873526] y [0.99750269]\n",
      "e 1 n 8400 pred [0.9572792] y [1.00221893]\n",
      "e 1 n 8600 pred [0.96943706] y [0.99984657]\n",
      "e 1 n 8800 pred [1.016774] y [1.0001516]\n",
      "e 1 n 9000 pred [0.94001985] y [1.00402001]\n",
      "e 1 n 9200 pred [1.0349754] y [1.00303132]\n",
      "e 1 n 9400 pred [0.9461748] y [1.00082783]\n",
      "e 1 n 9600 pred [0.9445722] y [1.00284661]\n",
      "e 1 n 9800 pred [1.0104305] y [0.99934204]\n",
      "e 1 n 10000 pred [0.9938839] y [1.00097242]\n",
      "e 1 n 10200 pred [1.0439432] y [1.0019402]\n",
      "e 1 n 10400 pred [0.9875087] y [1.00054425]\n",
      "e 1 n 10600 pred [0.9756865] y [0.99667798]\n",
      "e 1 n 10800 pred [0.9878329] y [1.00149223]\n",
      "e 1 n 11000 pred [1.0262198] y [0.98260827]\n",
      "e 1 n 11200 pred [1.0590674] y [1.00034015]\n",
      "e 1 n 11400 pred [1.0086708] y [0.99931553]\n",
      "e 1 n 11600 pred [0.99114996] y [0.99905131]\n",
      "e 1 n 11800 pred [0.9868484] y [0.99955435]\n",
      "e 1 n 12000 pred [0.9732408] y [1.00040618]\n",
      "e 1 n 12200 pred [0.95673984] y [1.00058586]\n",
      "e 1 n 12400 pred [0.98402935] y [1.00276516]\n",
      "e 1 n 12600 pred [1.0174663] y [0.99823662]\n",
      "e 1 n 12800 pred [1.0315764] y [0.99963299]\n",
      "e 1 n 13000 pred [0.9639442] y [0.99940519]\n",
      "e 1 n 13200 pred [1.0060595] y [1.0000254]\n",
      "e 1 n 13400 pred [1.0284818] y [1.00025478]\n",
      "e 1 n 13600 pred [1.0131214] y [0.99987575]\n",
      "e 1 n 13800 pred [1.0052646] y [0.99939557]\n",
      "e 1 n 14000 pred [0.98353183] y [0.99870122]\n",
      "e 1 n 14200 pred [1.0271286] y [1.00061643]\n",
      "e 1 n 14400 pred [1.0340272] y [1.00007187]\n",
      "e 1 n 14600 pred [0.992075] y [0.99951764]\n",
      "e 1 n 14800 pred [0.9845684] y [1.00000906]\n",
      "e 1 n 15000 pred [0.96646667] y [1.00037611]\n",
      "e 1 n 15200 pred [1.0420177] y [1.0006766]\n",
      "e 1 n 15400 pred [1.0109779] y [1.00175713]\n",
      "e 1 n 15600 pred [0.9906218] y [0.99887758]\n",
      "e 1 n 15800 pred [1.0325303] y [1.00006934]\n",
      "e 1 n 16000 pred [0.9692549] y [0.99846783]\n",
      "e 1 n 16200 pred [1.01352] y [1.00114295]\n",
      "e 1 n 16400 pred [0.99575645] y [1.00000261]\n",
      "e 1 n 16600 pred [0.95759135] y [0.99880802]\n",
      "e 1 n 16800 pred [1.0144572] y [0.99983777]\n",
      "e 1 n 17000 pred [0.9924707] y [1.00198776]\n",
      "e 1 n 17200 pred [1.0076736] y [0.99934144]\n",
      "e 1 n 17400 pred [0.9991557] y [1.00491125]\n",
      "e 1 n 17600 pred [1.0078366] y [1.00196965]\n",
      "e 1 n 17800 pred [1.0054841] y [1.00139025]\n",
      "e 1 n 18000 pred [0.98693466] y [1.00077405]\n",
      "e 1 n 18200 pred [1.0494081] y [0.9993385]\n",
      "e 1 n 18400 pred [1.0099787] y [1.00027379]\n",
      "e 1 n 18600 pred [1.0328469] y [0.99923005]\n",
      "e 1 n 18800 pred [1.0091933] y [1.00026681]\n",
      "e 1 n 19000 pred [0.9795838] y [1.00012962]\n",
      "e 1 n 19200 pred [0.9915655] y [0.99865327]\n",
      "e 1 n 19400 pred [0.9894445] y [1.00153058]\n",
      "e 1 n 19600 pred [0.99340737] y [0.99897718]\n",
      "e 1 n 19800 pred [1.0335305] y [1.00141362]\n",
      "e 1 n 20000 pred [0.97352517] y [0.99936823]\n",
      "e 1 n 20200 pred [0.96243775] y [0.99996916]\n",
      "e 1 n 20400 pred [1.0043288] y [1.00039758]\n",
      "e 1 n 20600 pred [1.0129762] y [0.99988325]\n",
      "e 1 n 20800 pred [0.9952624] y [1.00158336]\n",
      "e 1 n 21000 pred [1.004809] y [0.99842145]\n",
      "e 1 n 21200 pred [1.0230153] y [0.99447295]\n",
      "e 1 n 21400 pred [0.9872852] y [1.00049123]\n",
      "e 1 n 21600 pred [0.9671315] y [0.9987318]\n",
      "e 1 n 21800 pred [0.9891015] y [0.99939769]\n",
      "e 1 n 22000 pred [0.9788915] y [1.00321769]\n",
      "e 1 n 22200 pred [1.0072385] y [1.00076292]\n",
      "e 1 n 22400 pred [0.9836908] y [0.99926742]\n",
      "e 1 n 22600 pred [0.97828454] y [1.00044928]\n",
      "e 1 n 22800 pred [1.0398295] y [0.99908409]\n",
      "e 1 n 23000 pred [0.9579802] y [0.99935909]\n",
      "e 1 n 23200 pred [0.98824924] y [0.99810104]\n",
      "e 1 n 23400 pred [0.9900324] y [1.00645633]\n",
      "e 1 n 23600 pred [0.988302] y [0.9994623]\n",
      "e 1 n 23800 pred [1.0383043] y [1.00382306]\n",
      "e 1 n 24000 pred [1.0126611] y [1.00014376]\n",
      "e 1 n 24200 pred [0.9311685] y [0.99913745]\n",
      "e 1 n 24400 pred [0.98306394] y [0.99911151]\n",
      "e 1 n 24600 pred [1.007995] y [1.00007402]\n",
      "e 1 n 24800 pred [1.0157951] y [1.00042394]\n",
      "e 1 n 25000 pred [0.95590633] y [1.00134289]\n",
      "e 1 n 25200 pred [1.0413364] y [1.00017781]\n",
      "e 1 n 25400 pred [0.9854957] y [1.00250526]\n",
      "e 1 n 25600 pred [1.003869] y [0.99837791]\n",
      "e 1 n 25800 pred [0.9789133] y [0.99990516]\n",
      "e 1 n 26000 pred [1.0233759] y [0.99863584]\n",
      "e 1 n 26200 pred [0.97469664] y [1.0025812]\n",
      "e 1 n 26400 pred [1.0466591] y [1.00048263]\n",
      "e 1 n 26600 pred [0.9879826] y [0.99726387]\n",
      "e 1 n 26800 pred [1.0092236] y [0.99904676]\n",
      "e 1 n 27000 pred [0.99534506] y [1.00096071]\n",
      "e 1 n 27200 pred [0.9629519] y [0.99772217]\n",
      "e 1 n 27400 pred [1.0007229] y [1.00152503]\n",
      "e 1 n 27600 pred [1.0070837] y [0.99990448]\n",
      "e 1 n 27800 pred [1.0287871] y [1.00100518]\n",
      "e 1 n 28000 pred [1.0129975] y [0.99941292]\n",
      "e 1 n 28200 pred [1.003456] y [0.99951916]\n",
      "e 1 n 28400 pred [0.99332833] y [0.99971501]\n",
      "e 1 n 28600 pred [0.9772625] y [0.99968314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 1 n 28800 pred [1.0116262] y [0.99922161]\n",
      "e 1 n 29000 pred [0.95544535] y [0.99927885]\n",
      "e 1 n 29200 pred [0.9974744] y [0.99933793]\n",
      "e 1 n 29400 pred [1.009965] y [0.99989204]\n",
      "e 1 n 29600 pred [1.0171722] y [1.00024454]\n",
      "e 1 n 29800 pred [0.97386485] y [1.0021755]\n",
      "e 1 n 30000 pred [0.9744969] y [1.01215043]\n",
      "e 1 n 30200 pred [0.9995896] y [1.00179286]\n",
      "e 1 n 30400 pred [1.0013376] y [0.99970387]\n",
      "e 1 n 30600 pred [0.9375251] y [1.00047395]\n",
      "e 1 n 30800 pred [1.0014224] y [0.99788239]\n",
      "e 1 n 31000 pred [1.0235938] y [1.00541544]\n",
      "e 1 n 31200 pred [0.997221] y [0.99799607]\n",
      "e 1 n 31400 pred [0.97195834] y [0.99928333]\n",
      "e 1 n 31600 pred [1.0070661] y [0.99973626]\n",
      "e 1 n 31800 pred [1.0161536] y [0.99992112]\n",
      "e 1 n 32000 pred [0.9834284] y [0.99826323]\n",
      "e 1 n 32200 pred [1.0152134] y [1.00212437]\n",
      "e 1 n 32400 pred [0.9995555] y [0.99909982]\n",
      "e 1 n 32600 pred [1.0032285] y [0.99913419]\n",
      "e 1 n 32800 pred [0.98304] y [1.00027122]\n",
      "e 1 n 33000 pred [1.011956] y [0.99899116]\n",
      "e 1 n 33200 pred [1.0284988] y [1.00727656]\n",
      "e 1 n 33400 pred [1.0406789] y [0.99956431]\n",
      "e 1 n 33600 pred [0.9964297] y [1.00157124]\n",
      "e 1 n 33800 pred [0.98974603] y [1.00049642]\n",
      "e 1 n 34000 pred [0.98103774] y [0.99955513]\n",
      "e 1 n 34200 pred [1.0085053] y [0.99974802]\n",
      "e 1 n 34400 pred [1.0197263] y [1.00036449]\n",
      "e 1 n 34600 pred [1.0062226] y [1.00251142]\n",
      "e 1 n 34800 pred [0.99699104] y [1.00071499]\n",
      "e 1 n 35000 pred [0.9646682] y [0.9985603]\n",
      "e 1 n 35200 pred [1.016176] y [1.00064503]\n",
      "e 1 n 35400 pred [1.0168658] y [1.00059707]\n",
      "e 1 n 35600 pred [1.0430758] y [1.00073957]\n",
      "e 1 n 35800 pred [0.9985832] y [1.01301473]\n",
      "e 1 n 36000 pred [0.9765464] y [0.99874791]\n",
      "e 1 n 36200 pred [0.99441975] y [1.000567]\n",
      "e 1 n 36400 pred [1.0059069] y [1.00205536]\n",
      "e 1 n 36600 pred [1.0181484] y [1.00121351]\n",
      "e 1 n 36800 pred [1.0269139] y [1.00005837]\n",
      "e 1 n 37000 pred [0.9770397] y [0.99957705]\n",
      "e 1 n 37200 pred [1.007074] y [0.99963435]\n",
      "e 1 n 37400 pred [0.98685163] y [1.00070226]\n",
      "e 1 n 37600 pred [1.0388182] y [0.99857378]\n",
      "e 1 n 37800 pred [1.0170857] y [0.99936839]\n",
      "e 1 n 38000 pred [1.0494226] y [0.99927964]\n",
      "e 1 n 38200 pred [1.0014161] y [1.00350896]\n",
      "e 1 n 38400 pred [0.98881096] y [0.99983769]\n",
      "e 1 n 38600 pred [1.0245644] y [1.00044822]\n",
      "e 1 n 38800 pred [1.0105577] y [1.00065078]\n",
      "e 1 n 39000 pred [1.0053835] y [0.99852306]\n",
      "e 1 n 39200 pred [0.9982856] y [0.99973262]\n",
      "e 1 n 39400 pred [0.9875751] y [0.99965672]\n",
      "e 1 n 39600 pred [1.0283625] y [0.99946376]\n",
      "e 1 n 39800 pred [0.98423016] y [0.99975566]\n",
      "e 1 n 40000 pred [1.0217254] y [0.99949535]\n",
      "e 1 n 40200 pred [0.98247397] y [0.99916456]\n",
      "e 1 n 40400 pred [1.0227935] y [1.00076421]\n",
      "e 1 n 40600 pred [0.9683806] y [1.00077829]\n",
      "e 1 n 40800 pred [0.99961376] y [1.0016409]\n",
      "e 1 n 41000 pred [0.98137707] y [1.00084602]\n",
      "e 1 n 41200 pred [0.97823805] y [0.99830401]\n",
      "e 1 n 41400 pred [1.0088371] y [0.99987012]\n",
      "e 1 n 41600 pred [1.0091691] y [1.001125]\n",
      "e 1 n 41800 pred [0.997213] y [1.00014154]\n",
      "e 1 n 42000 pred [0.9972966] y [0.99957319]\n",
      "e 1 n 42200 pred [1.0135922] y [0.99944181]\n",
      "e 1 n 42400 pred [1.0165693] y [1.00021338]\n",
      "e 1 n 42600 pred [1.0360174] y [1.0007699]\n",
      "e 1 n 42800 pred [1.0080827] y [1.00019987]\n",
      "e 1 n 43000 pred [0.9558891] y [0.9997942]\n",
      "e 1 n 43200 pred [0.9810271] y [1.00218702]\n",
      "e 1 n 43400 pred [0.98568153] y [0.99837254]\n",
      "e 1 n 43600 pred [0.99767834] y [1.00055638]\n",
      "e 1 n 43800 pred [1.0159858] y [1.00092206]\n",
      "e 1 n 44000 pred [1.0001336] y [1.00023935]\n",
      "e 1 n 44200 pred [1.015386] y [0.99753731]\n",
      "e 1 n 44400 pred [0.97315246] y [0.99902898]\n",
      "e 1 n 44600 pred [0.9996171] y [0.99936908]\n",
      "e 1 n 44800 pred [0.99058014] y [0.99935021]\n",
      "e 1 n 45000 pred [1.0199479] y [0.99997974]\n",
      "e 1 n 45200 pred [1.014754] y [1.00126568]\n",
      "e 1 n 45400 pred [1.0141433] y [0.99888227]\n",
      "e 1 n 45600 pred [0.988457] y [1.00103054]\n",
      "e 1 n 45800 pred [1.0076239] y [0.99960078]\n",
      "e 1 n 46000 pred [1.0317667] y [1.00006502]\n",
      "mean 0.023685093940208072 batch_loss 0.021703232564360925\n",
      "e 2 n 0 pred [0.9803587] y [1.00072192]\n",
      "e 2 n 200 pred [1.0038587] y [0.99900939]\n",
      "e 2 n 400 pred [0.9968513] y [1.00021762]\n",
      "e 2 n 600 pred [0.9784125] y [1.00051352]\n",
      "e 2 n 800 pred [1.0275568] y [1.00030326]\n",
      "e 2 n 1000 pred [0.98963195] y [1.01002872]\n",
      "e 2 n 1200 pred [1.0136158] y [1.00117947]\n",
      "e 2 n 1400 pred [1.0129057] y [0.99902285]\n",
      "e 2 n 1600 pred [0.970792] y [0.99744173]\n",
      "e 2 n 1800 pred [1.0323243] y [1.00106211]\n",
      "e 2 n 2000 pred [1.0384918] y [1.00153418]\n",
      "e 2 n 2200 pred [1.0158484] y [1.00158647]\n",
      "e 2 n 2400 pred [0.9741007] y [0.99942879]\n",
      "e 2 n 2600 pred [0.9814919] y [0.99958446]\n",
      "e 2 n 2800 pred [0.9660797] y [0.99923121]\n",
      "e 2 n 3000 pred [1.0144119] y [0.99910217]\n",
      "e 2 n 3200 pred [0.943057] y [1.00134804]\n",
      "e 2 n 3400 pred [1.0056171] y [0.99933574]\n",
      "e 2 n 3600 pred [0.9774345] y [1.00098822]\n",
      "e 2 n 3800 pred [0.9914196] y [0.99991441]\n",
      "e 2 n 4000 pred [1.0283937] y [1.00151856]\n",
      "e 2 n 4200 pred [0.98374414] y [0.99906598]\n",
      "e 2 n 4400 pred [0.9803419] y [0.99953338]\n",
      "e 2 n 4600 pred [1.0037503] y [1.00046631]\n",
      "e 2 n 4800 pred [0.9812862] y [0.99981377]\n",
      "e 2 n 5000 pred [0.9583593] y [0.99983971]\n",
      "e 2 n 5200 pred [0.9844744] y [0.99831714]\n",
      "e 2 n 5400 pred [1.0102029] y [1.0006117]\n",
      "e 2 n 5600 pred [1.0559088] y [1.00080338]\n",
      "e 2 n 5800 pred [0.98002213] y [0.99919751]\n",
      "e 2 n 6000 pred [0.97938895] y [0.99959041]\n",
      "e 2 n 6200 pred [1.0080336] y [0.99891068]\n",
      "e 2 n 6400 pred [0.9864405] y [1.00286188]\n",
      "e 2 n 6600 pred [1.0020624] y [1.00038751]\n",
      "e 2 n 6800 pred [0.9705968] y [1.00030093]\n",
      "e 2 n 7000 pred [0.9897744] y [1.00137166]\n",
      "e 2 n 7200 pred [1.0102042] y [1.00088546]\n",
      "e 2 n 7400 pred [0.9661172] y [1.00059328]\n",
      "e 2 n 7600 pred [0.9847458] y [1.00062029]\n",
      "e 2 n 7800 pred [0.9732118] y [1.00117674]\n",
      "e 2 n 8000 pred [0.9938908] y [1.00058009]\n",
      "e 2 n 8200 pred [1.013514] y [0.99750269]\n",
      "e 2 n 8400 pred [0.9949347] y [1.00221893]\n",
      "e 2 n 8600 pred [1.009739] y [0.99984657]\n",
      "e 2 n 8800 pred [1.0035667] y [1.0001516]\n",
      "e 2 n 9000 pred [1.008826] y [1.00402001]\n",
      "e 2 n 9200 pred [0.98024225] y [1.00303132]\n",
      "e 2 n 9400 pred [0.9850267] y [1.00082783]\n",
      "e 2 n 9600 pred [0.97895634] y [1.00284661]\n",
      "e 2 n 9800 pred [1.0140885] y [0.99934204]\n",
      "e 2 n 10000 pred [1.0035279] y [1.00097242]\n",
      "e 2 n 10200 pred [0.97811866] y [1.0019402]\n",
      "e 2 n 10400 pred [0.99597883] y [1.00054425]\n",
      "e 2 n 10600 pred [1.0387226] y [0.99667798]\n",
      "e 2 n 10800 pred [0.9947789] y [1.00149223]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-13e969a0dd4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                  model.opt],\n\u001b[0;32m---> 21\u001b[0;31m                                                  feed_dict=feed)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    for e in range(epochs):\n",
    "        total_loss=0\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        n_batches=0\n",
    "        for x, y in get_batch():\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.initial_state:new_state\n",
    "                    }\n",
    "           \n",
    "            batch_loss, new_state, y_hat, _ = sess.run([model.loss,\n",
    "                                                 model.final_state,\n",
    "                                                 model.logits,\n",
    "                                                 model.opt],\n",
    "                                                 feed_dict=feed)\n",
    "           \n",
    "            if n_batches % 200 == 0:\n",
    "                print('e',e,'n',n_batches,'pred',y_hat[3],'y',y[3])#,'x',x[3][-1][-1])\n",
    "           \n",
    "            total_loss+= batch_loss**0.5\n",
    "            n_batches+=1           \n",
    "               \n",
    "        print('mean',total_loss/n_batches,'batch_loss',batch_loss**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
